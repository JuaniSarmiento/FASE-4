1.1. Transformación estructural del ecosistema del software
Durante la última década —y con una aceleración sin precedentes desde 2022— la inteligencia artificial generativa ha modificado de manera profunda y sistémica el desarrollo de software. Los modelos de lenguaje de gran escala (LLMs) y los modelos especializados en código (Code LLMs) no sólo automatizan tareas puntuales (autocompletado, pruebas, documentación), sino que introducen nuevas formas de interacción cognitiva entre humanos y sistemas de IA.
Este proceso no representa una mejora incremental, sino una reconfiguración estructural del ciclo de ingeniería de software. Los agentes de IA actúan como colaboradores cognitivos capaces de generar razonamientos, hipótesis y soluciones completas, lo que desplaza el rol tradicional del programador desde la autoría exclusiva del código hacia la curaduría, auditoría, supervisión y diseño de procesos híbridos humano–IA.

1.2. Mutación epistemológica: qué significa “saber programar” en la era de la IA
El advenimiento de la IA generativa transforma radicalmente la epistemología de la programación. “Saber programar” deja de equivaler a escribir código manualmente para convertirse en la capacidad de:
formular y descomponer problemas en términos operables para agentes de IA;


evaluar críticamente propuestas generadas algorítmicamente;


detectar inconsistencias, vulnerabilidades y alucinaciones;


sostener procesos de auditoría continua en entornos DevOps y MLOps;


documentar el razonamiento, la toma de decisiones y las justificaciones del proceso;


operar bajo criterios éticos, normativos y de gobernanza algorítmica.


La programación se redefine así como una actividad cognitiva distribuida, en la que el humano coordina, verifica y regula los aportes de la IA. Esta mutación exige competencias nuevas, tanto técnicas como metacognitivas, que las instituciones formativas aún no han incorporado de manera sistemática.

1.3. Brechas críticas en la formación universitaria en programación
Mientras la industria opera con modelos híbridos humano–IA, la formación universitaria mantiene prácticas heredadas que ya no garantizan evidencia válida del aprendizaje:
ejercicios manuales susceptibles de ser resueltos por IA sin trazas cognitivas;


trabajos prácticos centrados en la producción final, sin registro del proceso;


evaluaciones basadas en presunciones de autoría individual;


ausencia de análisis de razonamiento, decisiones y auditorías realizadas por el estudiante;


escasa integración de principios de gobernanza algorítmica.
CAPÍTULO 6 – MODELO AI-NATIVE Y ARQUITECTURA C4
6.1. Introducción general al modelo AI-Native
Los capítulos precedentes han establecido, por un lado, el marco teórico que permite conceptualizar a la inteligencia artificial generativa como tecnología cognitiva emergente y, por otro, el estado del arte empírico sobre su impacto en la programación, la cognición y la educación en Ciencias de la Computación. Sobre esta doble base conceptual y empírica, el presente capítulo introduce y desarrolla el modelo AI-Native propuesto por esta tesis como respuesta sistemática a las transformaciones identificadas.
El objetivo central de este capítulo es definir, formalizar y arquitecturar un modelo formativo integral que:
asume la presencia de IA generativa como condición estructural del ecosistema socio–técnico en el que se forman los programadores;


desplaza el foco desde la mera tolerancia regulatoria o la prohibición defensiva hacia un diseño curricular, pedagógico y tecnológico proactivo;


articula una arquitectura tecnológica con trazabilidad cognitiva, un modelo de evaluación centrado en procesos, un conjunto de submodelos de IA disciplinarios y un marco de gobernanza institucional explícito.


En términos de estructura, el capítulo se organiza en cuatro secciones principales:
La sección 6.2 explicita los principios, supuestos y objetivos del modelo AI-Native, situándolo como propuesta pedagógica, cognitiva y tecnológica diferenciada.


La sección 6.3 presenta una definición formal del modelo como sistema sociotécnico educativo de razonamiento híbrido humano–IA.


La sección 6.4 desarrolla la arquitectura C4 completa del ecosistema AI-Native, interpretada desde una perspectiva técnico–pedagógica y cognitiva.


La sección 6.5 describe la integración curricular y operacional del modelo en la Tecnicatura Universitaria en Programación con IA Nativa, vinculando la arquitectura con el plan de estudios, las actividades, las competencias y los dispositivos institucionales de implementación.


De este modo, el Capítulo 6 constituye el núcleo propositivo de la tesis: traduce los marcos conceptuales y la evidencia empírica en un modelo integral susceptible de ser implementado, pilotado y evaluado institucionalmente.

6.2. Principios, supuestos y objetivos del modelo AI-Native
El modelo AI-Native se construye sobre un conjunto explícito de supuestos cognitivos y tecnológicos, principios pedagógicos y objetivos formativos e institucionales. Su formulación precisa resulta crucial para que el modelo pueda ser evaluado, replicado y sometido a escrutinio según los estándares de calidad del sistema universitario y de los organismos de acreditación.
6.2.1. Supuestos cognitivos y tecnológicos
En coherencia con las teorías de cognición distribuida (Hutchins, 1995; Hollan et al., 2000) y cognición extendida (Clark & Chalmers, 1998), el modelo adopta los siguientes supuestos:
Programación como razonamiento híbrido humano–IA.
 En entornos con IA generativa, la programación se configura como una actividad de razonamiento híbrido: el agente humano ya no resuelve en soledad, sino en interacción con sistemas generativos que proponen, completan, corrigen y explican código.


IA generativa como tecnología cognitiva que redistribuye la carga.
 Los modelos generativos, y en particular los Code LLMs, funcionan como tecnologías cognitivas que redistribuyen la carga de esfuerzo entre:


la producción manual de código,


la evaluación crítica,


la verificación y el testing,


la planificación y la documentación (Sweller, 1988; Sweller et al., 1998).


Fragilidad epistémica estructural de la IA generativa.
 Las alucinaciones, los errores silenciosos, los sesgos y la opacidad no constituyen anomalías aisladas, sino limitaciones estructurales del paradigma generativo (Bender et al., 2021; Ji et al., 2023). En consecuencia, la formación no puede limitarse a enseñar un “uso instrumental” de estas herramientas; debe formar en auditoría, verificación y gobernanza de sistemas de IA.


Abundancia de trazas digitales de razonamiento.
 En entornos educativos híbridos, la interacción humano–IA genera una gran cantidad de trazas digitales de razonamiento (prompts, respuestas, versiones de código, decisiones intermedias, comentarios, commits), que, si son adecuadamente capturadas y organizadas, permiten pasar de una evaluación centrada en el producto a una evaluación centrada en el proceso cognitivo asistido–auditado.


Estos supuestos constituyen el punto de partida para la definición de los principios pedagógicos del modelo.
6.2.2. Principios pedagógicos del modelo AI-Native
Sobre los supuestos anteriores, el modelo AI-Native se articula en torno a cinco principios pedagógicos fundamentales:
Centralidad del razonamiento asistido–auditado.
 La IA se utiliza para hacer visible el razonamiento del estudiante, no para sustituirlo. El modelo propone un régimen de razonamiento asistido–auditado, en el cual la IA:


asiste en la exploración de alternativas,


obliga a explicitar decisiones,


pero no reemplaza la responsabilidad epistémica del estudiante.


Evaluación basada en procesos y trazabilidad cognitiva.
 La evidencia de aprendizaje deja de reducirse al código final y pasa a incluir:


prompts,


versiones de código,


explicaciones del estudiante,


registros de interacción con la IA,


decisiones de diseño y revisiones sucesivas.
 Esta evidencia se organiza en una base de trazabilidad cognitiva que se convierte en insumo principal de las rúbricas evaluativas AI-Native.


Competencias emergentes en programación con IA.
 El significado de “saber programar” se redefine para incluir, además de la competencia técnica clásica, la capacidad de:


especificar problemas de forma clara para agentes generativos,


auditar soluciones propuestas por sistemas de IA,


gestionar riesgos técnicos y éticos,


documentar decisiones en entornos híbridos humano–IA,


colaborar en equipos donde la IA actúa como co-agente.


Andamiaje cognitivo adaptativo.
 El apoyo que brinda la IA no es constante ni uniforme. Se ajusta al nivel del estudiante, al tipo de actividad y a los objetivos de aprendizaje. El sistema puede:


ofrecer más guía, ejemplos y explicaciones para estudiantes principiantes;


reducir la ayuda directa y aumentar la demanda crítica para estudiantes avanzados;


modular los modos de tutoría (socrático, explicativo, simulador, auditor).


Integración estructural de la gobernanza ética.
 Los marcos de gobernanza de IA (Floridi & Cowls, 2019; OECD, 2019; UNESCO, 2021; ISO/IEC 23894, 2023; IEEE, 2019) no se implementan como anexos declarativos, sino como componentes operativos del sistema. La gobernanza se vuelve parte de la experiencia formativa: el estudiante aprende a trabajar bajo restricciones éticas y normativas explícitas, internalizando criterios de uso responsable de IA.


6.2.3. Objetivos formativos, pedagógicos, tecnológicos e institucionales
En este marco, el modelo AI-Native persigue un conjunto de objetivos articulados en cuatro planos:
Objetivos formativos.


Desarrollar competencias técnicas sólidas en programación, integradas con competencias de interacción crítica con IA, auditoría de código generado y toma de decisiones responsable.


Promover formas avanzadas de autorregulación del aprendizaje en entornos híbridos humano–IA (Zimmerman, 2002).


Objetivos pedagógicos.


Reconfigurar las prácticas evaluativas, incorporando la trazabilidad cognitiva como eje central.


Utilizar la IA como agente pedagógico que acompaña proyectos, simulaciones y prácticas profesionalizantes, sin sustituir la mediación docente.


Objetivos tecnológicos.


Implementar una arquitectura modular, escalable y auditable, basada en estándares abiertos (FastAPI, LTI, Git, n8n, etc.).


Asegurar que todos los flujos de información con IA sean trazables y gobernados, permitiendo auditoría técnica, pedagógica y normativa.


Objetivos institucionales.


Dotar a la Tecnicatura de un modelo diferencial y sostenible, en línea con los lineamientos de calidad del sistema universitario y las recomendaciones internacionales sobre IA en educación.


Generar un marco replicable para otras carreras y facultades, contribuyendo a una transformación institucional más amplia hacia ecosistemas AI-Native.


Estos principios y objetivos preparan el terreno para la definición formal del modelo, presentada a continuación.

6.3. Definición formal del modelo AI-Native
A partir de los fundamentos expuestos, el modelo AI-Native se define formalmente como:
Un sistema sociotécnico educativo de razonamiento híbrido humano–IA, soportado por una arquitectura tecnológica de trazabilidad cognitiva completa, un modelo pedagógico centrado en la auditoría de procesos, un conjunto de submodelos de IA disciplinarios, mecanismos de gobernanza integrados y un diseño curricular orientado a competencias emergentes en entornos de programación asistida por modelos generativos.
Esta definición concentra cinco dimensiones constitutivas:
Sistema sociotécnico educativo.
 El AI-Native integra agentes humanos (estudiantes, docentes, gestión académica, referentes de calidad y ética), plataformas digitales (Moodle, Git, servicios de IA, bases de datos), marcos normativos y prácticas pedagógicas específicas. La unidad de análisis es la ecología institucional de enseñanza–aprendizaje, y no sólo el software o el aula en línea.


Razonamiento híbrido humano–IA.
 La resolución de problemas en programación se despliega como un proceso distribuido entre el sujeto y los sistemas generativos (Hutchins, 1995; Clark & Chalmers, 1998). El modelo AI-Native propone un régimen de razonamiento asistido–auditado: la IA es parte activa del sistema cognitivo efectivo, pero el estudiante conserva y ejercita la responsabilidad epistémica.


Arquitectura tecnológica con trazabilidad cognitiva completa.
 La arquitectura no se limita a integrar servicios; está diseñada para capturar y reconstruir el proceso cognitivo detrás de cada solución: prompts, respuestas, versiones de código, decisiones, riesgos detectados, intervenciones docentes. Esta trazabilidad cognitiva N4 se convierte en la fuente principal para la evaluación formativa y sumativa.


Modelo pedagógico de auditoría de procesos.
 La evaluación se desplaza de una lógica producto–céntrica (el código que funciona) a una lógica proceso–céntrica que examina cómo se llegó a la solución, qué papel desempeñó la IA, qué decisiones tomó el estudiante y con qué justificación. La IA es parte del proceso formativo, pero también objeto de crítica y auditoría.


Submodelos de IA disciplinarios y gobernanza integrada.
 El AI-Native incluye submodelos IA especializados (programación, DevOps, seguridad, simulación de clientes, etc.), coordinados por un ai-gateway que implementa la gobernanza. Esto implica incorporar de manera operativa marcos de gestión del riesgo, ética y trazabilidad (ISO/IEC 23894, UNESCO, OECD, IEEE), de modo que la interacción con la IA esté regulada, documentada y sea susceptible de rendición de cuentas.


Enfoque curricular orientado a competencias emergentes.
 Finalmente, el modelo reconfigura la noción de competencia profesional en programación: incluye la capacidad de especificar, interactuar, auditar y gobernar sistemas de IA. El currículum, las actividades y las prácticas profesionalizantes se diseñan explícitamente en función de este objetivo.


En síntesis, el modelo AI-Native no se reduce a la adopción de nuevas herramientas, sino que propone una reconfiguración integral de la formación en programación, articulando dimensiones cognitivas, pedagógicas, tecnológicas e institucionales.

6.4. Arquitectura C4 del ecosistema AI-Native
La definición formal del modelo se traduce en una arquitectura concreta que debe ser implementable, auditable y evaluable. Para ello, la tesis adopta y extiende el marco C4 (Context, Containers, Components, Code) hacia una lectura socio–técnica y cognitiva, organizada en cuatro niveles:
Nivel 1 – Contexto: ubica al ecosistema AI-Native en relación con estudiantes, docentes, gestión académica, servicios de IA, sistemas institucionales y marcos normativos.


Nivel 2 – Contenedores: describe los sistemas lógicos y físicos (Moodle, ai-gateway, Git, n8n, base N4, módulos de gobernanza, etc.) junto con sus responsabilidades técnicas, cognitivas, pedagógicas y normativas.


Nivel 3 – Componentes: detalla la descomposición interna del ai-gateway, núcleo cognitivo y de gobernanza, en módulos que implementan autenticación, análisis de prompts, razonamiento pedagógico, gestión de riesgo, orquestación de LLMs y trazabilidad.


Nivel 4 – Dinámica: modela los flujos de interacción humano–IA–sistema en tiempo real, representando al ecosistema como una máquina cognitiva híbrida que opera en cada actividad formativa.


A continuación se sintetizan los ejes principales de los niveles 2, 3 y 4. Los diagramas y descripciones detalladas se desarrollan en los Anexos técnicos correspondientes.
6.4.1. Nivel 2 – Contenedores: ecosistema técnico–pedagógico
El Nivel 2 identifica nueve contenedores centrales:
A. Moodle-LMS (aula virtual UTN)
 B. ai-gateway (FastAPI + orquestación cognitiva)
 C. Servicios de IA generativa (LLM externos o locales)
 D. Repositorio Git institucional
 E. Base de datos de trazabilidad cognitiva N4
 F. n8n – orquestador institucional de flujos
 G. Sistema de gobernanza, ética y riesgo
 H. Sistema de observabilidad, logging y telemetría
 I. Docente y estudiante como agentes cognitivos
Cada contenedor se caracteriza por:
Responsabilidad técnica: funciones de software o infraestructura que cumple.


Responsabilidad cognitiva: papel en la distribución y externalización del razonamiento.


Responsabilidad pedagógica: contribución a la formación y a la evaluación.


Responsabilidad normativa y de gobernanza: marco legal, ético y de riesgo que operacionaliza.


Interfaces: conexiones con otros contenedores y protocolos utilizados.


Riesgos asociados: vulnerabilidades técnicas, cognitivas o éticas implicadas.


Dependencias: otros contenedores necesarios para su funcionamiento correcto.


La incorporación explícita de dimensiones cognitivas y pedagógicas en la descripción C4 constituye uno de los aportes originales de la tesis: la arquitectura deja de ser meramente funcional para convertirse en arquitectura cognitivo–pedagógica.
6.4.2. Nivel 3 – Componentes internos del ai-gateway
En el Nivel 3, el ai-gateway se descompone en siete componentes, cada uno con responsabilidades técnicas, cognitivas, pedagógicas y normativas claramente definidas:
C1. Autenticación, Autorización y LTI-Mapping.
 Determina quién es el usuario, qué rol cumple, qué niveles de agencia puede asumir la IA y qué modos de intervención están habilitados para cada cátedra y actividad.


C2. Ingesta y Comprensión de Prompt (IPC).
 Analiza la intención, estructura y calidad cognitiva del prompt, detecta señales de delegación excesiva y puede requerir al estudiante mayor explicitación o reformulación.


C3. Motor de Razonamiento Cognitivo–Pedagógico (CRPE).
 Selecciona el modo cognitivo (tutor, auditor, simulador, crítico–reflexivo), evalúa profundidad y coherencia del razonamiento y genera feedback estructurado acorde a los objetivos de la actividad.


C4. Gobernanza, Seguridad y Riesgo (GSR).
 Implementa los marcos de riesgo y ética (ISO/IEC 23894, UNESCO, OECD, IEEE), protege datos, clasifica riesgos técnicos y cognitivos, y garantiza la trazabilidad normativa de cada interacción.


C5. LLM-Orchestrator (multi–proveedor).
 Orquesta la interacción con distintos modelos de IA, seleccionando el más apropiado según dominio, riesgo, costo y requisitos pedagógicos y de gobernanza.


C6. Trazabilidad Cognitiva N4.
 Registra cada interacción (prompt, respuesta, análisis, decisión) y la vincula con artefactos de código, tareas y rúbricas, construyendo el mapa de pensamiento híbrido del estudiante.


C7. Integración con Git / n8n / Moodle.
 Conecta el ai-gateway con los sistemas institucionales y de automatización, cerrando el ciclo pedagógico–técnico–institucional mediante sincronización de actividades, commits, flujos de retroalimentación y registros evaluativos.


El diseño de estos componentes materializa, a nivel arquitectónico, el modelo de razonamiento asistido–auditado y la integración de la gobernanza ética en la operación cotidiana del sistema.
6.4.3. Nivel 4 – Dinámica: operación en tiempo real
El Nivel 4 modela el funcionamiento del ecosistema AI-Native durante una actividad formativa típica. La tesis describe un flujo universal de 11 fases que va desde la publicación de la actividad en Moodle hasta la consolidación de evidencias en N4 y los sistemas de gestión académica. En forma sintética, la dinámica incluye:
inicialización del contexto pedagógico vía LTI desde Moodle;


análisis del primer prompt por el componente IPC;


selección del modo cognitivo y del modelo de IA apropiado por el CRPE y el LLM-Orchestrator;


generación y filtrado de la respuesta de la IA, bajo control del módulo GSR;


iteración estudiante–IA con registro de decisiones y razonamientos parciales;


commits en Git como trazas de evolución técnica del código;


activación de flujos n8n para retroalimentación automática, alertas y monitoreo;


consolidación de la trazabilidad cognitiva en N4;


intervención docente sobre la base de evidencias procesuales;


cierre evaluativo con integración a calificaciones y reportes;


alimentación de indicadores e informes para instancias de gestión y calidad.


Este modelo dinámico convierte a la arquitectura en una máquina cognitiva híbrida, donde cada elemento técnico está al servicio de la visibilización, acompañamiento y evaluación del razonamiento humano en entornos asistidos por IA.

6.5. Integración curricular y operacional del modelo AI-Native
La arquitectura y el modelo pedagógico descritos deben traducirse en decisiones curriculares y operacionales concretas para la Tecnicatura Universitaria en Programación con IA Nativa. Esta sección explicita ese tránsito desde el diseño conceptual hacia la implementación educativa.
6.5.1. Articulación con el plan de estudios y el perfil de egreso
El modelo AI-Native se integra al plan de estudios en tres niveles:
Nivel macro–curricular (perfil de egreso y estructura de la carrera).


El perfil de egreso incorpora explícitamente competencias de programación asistida por IA, auditoría de código generado, gestión de riesgos y gobernanza básica de sistemas de IA.


La malla se organiza de modo tal que la IA generativa esté presente —con distinta intensidad— en todos los semestres, evitando su confinamiento a una única asignatura optativa o aislada.


Nivel meso–curricular (asignaturas y trayectos formativos).


Se definen trayectos AI-Native que atraviesan materias de programación, arquitectura de software, bases de datos, DevOps y seguridad.


En cada asignatura se especifica el tipo de interacción con IA (tutoría, simulación de rol, auditoría, etc.), el peso de la trazabilidad cognitiva y los indicadores de logro asociados.


Nivel micro–curricular (actividades, proyectos, evaluaciones).


Las actividades prácticas incluyen explícitamente el uso del ecosistema AI-Native: el estudiante interactúa con IA, pero debe documentar, justificar y auditar sus decisiones.


Las rúbricas contemplan dimensiones asociadas al uso crítico de IA: capacidad de detectar errores del modelo, identificar sesgos, justificar la aceptación o rechazo de propuestas y razonar sobre riesgos técnicos y éticos.


6.5.2. Tipología de actividades AI-Native
En coherencia con la arquitectura propuesta, la tesis identifica una tipología de actividades recurrentes:
Actividades de co–programación crítica.
 El estudiante trabaja con un Code LLM como “par programador artificial”, pero debe justificar las decisiones, documentar su razonamiento y evidenciar la auditoría del código sugerido por la IA.


Actividades de auditoría de código generado por IA.
 La IA produce una solución inicial y el estudiante debe auditarla, detectando errores, riesgos de seguridad, problemas de rendimiento o decisiones de diseño discutibles.


Simulaciones con IA en roles contextuales.
 La IA actúa como cliente, product owner, revisor de código sénior, equipo de operaciones, entre otros, generando escenarios de interacción cercanos al mundo profesional.


Actividades de meta–reflexión y gobernanza.
 El estudiante analiza logs de interacción, trazas N4, políticas de uso de IA y marcos éticos, discutiendo riesgos, dilemas y posibles decisiones institucionales.


En todos los casos, la arquitectura C4 constituye la infraestructura que hace posible el registro, análisis y evaluación de estos procesos.
6.5.3. Mecanismos de evaluación y acreditación AI-Native
El modelo AI-Native introduce cambios significativos en la evaluación:
La nota final de un trabajo práctico o proyecto ya no deriva sólo del código final, sino de un conjunto de evidencias: razonamiento explicitado, decisiones justificadas, interacción con IA, trayectoria de commits, análisis de riesgos y calidad de la documentación.


Las rúbricas AI-Native ponderan:


la calidad técnica del código,


la calidad del razonamiento y de la auditoría,


el uso crítico de IA,


el cumplimiento de principios éticos y normativos,


la capacidad de reflexión sobre el propio proceso de aprendizaje.


La acreditación de asignaturas y prácticas profesionalizantes se apoya en informes generados a partir de la base N4, que presentan una síntesis estructurada de las trayectorias cognitivas y técnicas del estudiante. Este enfoque permite superar la tensión, ampliamente documentada en la literatura, entre la disponibilidad de IA generativa y la validez de los dispositivos evaluativos tradicionales.
6.5.4. Condiciones institucionales para la implementación
Finalmente, la implementación del modelo AI-Native requiere un conjunto de condiciones institucionales:
Infraestructura tecnológica adecuada.
 Capacidad para desplegar y mantener el ai-gateway, integrar Moodle y n8n, gestionar repositorios Git institucionales y operar servicios de IA bajo criterios de seguridad y protección de datos.


Capacitación docente específica.
 Formación en uso pedagógico de IA, diseño de actividades AI-Native, lectura e interpretación de trazas cognitivas, y comprensión básica de marcos de gobernanza y riesgo.


Políticas institucionales claras.
 Lineamientos de uso responsable de IA, protocolos de protección de datos, reglas de integridad académica adaptadas a entornos híbridos y mecanismos de reclamo y revisión para estudiantes y docentes.


Articulación con instancias de calidad y ética.
 Integración del modelo con comisiones de seguimiento, áreas de innovación educativa y dispositivos de evaluación interna y externa (incluyendo procesos de acreditación).


La tesis sostiene que, bajo estas condiciones, el modelo AI-Native es implementable y evaluable en la Tecnicatura Universitaria en Programación con IA Nativa, y que ofrece un marco robusto y transferible para futuras extensiones a otras carreras y niveles formativos dentro del sistema universitario.

















6.6. Submodelo 1 – Tutor IA disciplinar cognitivo (T-IA-Cog)
El primer submodelo operativo del ecosistema AI-Native es el Tutor IA disciplinar cognitivo (T-IA-Cog). Este submodelo formaliza el comportamiento de la IA cuando asume un rol de tutoría en actividades de programación, proyectos guiados y prácticas profesionalizantes, bajo el régimen de razonamiento asistido–auditado definido en este capítulo. Su función no es resolver tareas en lugar del estudiante, sino organizar, extender y hacer visible el proceso de razonamiento, manteniendo la responsabilidad epistémica en el sujeto humano.
Desde la perspectiva del modelo AI-Native, el T-IA-Cog constituye la pieza clave que traduce los principios de cognición distribuida y extendida, carga cognitiva y autorregulación del aprendizaje en interacciones concretas entre estudiante e IA, mediadas por el ai-gateway y la arquitectura C4.
6.6.1. Fundamentación cognitiva y pedagógica
El diseño del T-IA-Cog se apoya en cuatro pilares teóricos principales:
Cognición distribuida
 En línea con Hutchins (1995) y Hollan et al. (2000), la programación se entiende como un proceso de resolución de problemas que tiene lugar en un sistema socio–técnico compuesto por personas, artefactos y entornos organizados. El T-IA-Cog se incorpora como uno de esos artefactos cognitivos, contribuyendo a la generación, reestructuración y evaluación de representaciones, pero sin absorber el control ni la agencia final del proceso.


Cognición extendida
 De acuerdo con la tesis de la mente extendida (Clark & Chalmers, 1998; Clark, 2016), ciertos artefactos pueden integrarse funcionalmente al sistema cognitivo efectivo del sujeto cuando cumplen roles epistémicos estables. El T-IA-Cog opera como una extensión funcional del sistema de pensamiento del estudiante: le ayuda a descomponer problemas, explicitar supuestos y explorar alternativas, pero lo obliga a justificar y validar sus decisiones.


Teoría de la carga cognitiva
 La intervención del T-IA-Cog busca redistribuir la carga cognitiva (Sweller, 1988; Sweller et al., 1998). Reduce carga extrínseca vinculada a tareas mecánicas (recordar detalles sintácticos, reproducir patrones triviales de código) y favorece la carga germinal asociada al diseño de soluciones, la comprensión de conceptos, la comparación de enfoques y la verificación crítica de propuestas. El objetivo no es “alivianar” el esfuerzo, sino redirigirlo hacia procesos cognitivos de mayor valor formativo.


Autorregulación y metacognición
 Siguiendo a Zimmerman (2002), el T-IA-Cog está diseñado para apoyar al estudiante en los tres momentos de la autorregulación: planificación, monitoreo y evaluación. En lugar de proporcionar respuestas directas, el tutor induce al estudiante a formular objetivos, explicitar estrategias, revisar sus propios errores y reflexionar sobre el uso que hace de la IA generativa.


En síntesis, el T-IA-Cog es concebido como un agente de andamiaje cognitivo y metacognitivo, que amplifica ciertas capacidades del estudiante sin sustituirlas, y que opera bajo reglas pedagógicas y éticas explícitas.
6.6.2. Rol formativo y reglas de actuación
El submodelo T-IA-Cog define el comportamiento esperado de la IA cuando funciona como tutor disciplinar en programación. Su rol formativo puede sintetizarse en los siguientes ejes:
Guía del razonamiento, no proveedor de soluciones
 El tutor orienta el proceso de pensamiento del estudiante mediante preguntas, reformulaciones y pistas graduadas. Evita, salvo en fases muy iniciales o diagnósticas, entregar soluciones completas sin mediación.


Promoción de la explicitación
 El T-IA-Cog solicita que el estudiante explique qué pretende resolver, cuál es su plan, qué alternativas consideró y por qué descarta determinadas opciones. De este modo, convierte el razonamiento implícito en discurso compartido, recuperable por la base de trazabilidad N4.


Prevención de la delegación acrítica
 Cuando detecta patrones de “delegación total” (por ejemplo, prompts del tipo “hacé todo el código por mí”), el tutor responde pidiendo mayor especificación, descomposición del problema o justificación del enfoque, y puede rechazar solicitudes que vulneren las reglas de integridad académica fijadas en la gobernanza institucional.


Refuerzo de fundamentos conceptuales
 Frente a errores recurrentes o dudas superficiales, el T-IA-Cog remite a principios, invariantes y estructuras conceptuales (por ejemplo, diferencias entre recursión e iteración, entre acoplamiento y cohesión, entre pruebas de caja negra y caja blanca), en lugar de limitarse a corregir el código puntual.


Estas funciones se plasman en un conjunto de reglas de actuación pedagógica, parametrizables por cátedra y nivel, entre las que se incluyen:
Priorizar preguntas sobre respuestas directas.


Exigir justificación cuando el estudiante adopta una solución propuesta por la IA.


Escalar la dificultad cognitiva de las intervenciones conforme aumenta la competencia del estudiante.


Registrar explícitamente en la trazabilidad N4 los momentos en que el estudiante:


formula hipótesis,


cambia de estrategia,


corrige errores detectados por sí mismo,


critica salidas de la IA.


De este modo, el T-IA-Cog opera como un mediador sistemático del razonamiento más que como un generador de productos.
6.6.3. Arquitectura funcional dentro del ai-gateway
Arquitectónicamente, el T-IA-Cog no es un servicio aislado, sino un modo operativo específico del ai-gateway, tal como fue descrito en la sección 6.4.2. En particular:
Se implementa como una configuración del Motor de Razonamiento Cognitivo–Pedagógico (CRPE), que define:


el tipo de intervenciones permitidas,


el grado de ayuda máximo,


las políticas de devolución (pregunta, pista, contraejemplo, explicación parcial, etc.),


los criterios para cambiar de modo (por ejemplo, de tutoría explicativa a tutoría socrática).


Interactúa estrechamente con:


C2 – Ingesta y Comprensión de Prompt (IPC), que clasifica el tipo de solicitud del estudiante, detecta señales de delegación excesiva y etiqueta el estado cognitivo estimado (exploración, planificación, implementación, depuración).


C4 – Gobernanza, Seguridad y Riesgo (GSR), que bloquea o reconfigura la respuesta cuando la interacción potencialmente vulnera normas de integridad académica o de uso responsable de IA.


C6 – Trazabilidad Cognitiva N4, que captura cada episodio de tutoría (prompt, respuesta, repreguntas, decisiones del estudiante) y lo vincula con las rúbricas de evaluación de la actividad.


Sus parámetros pedagógicos (por ejemplo, proporción de pistas, longitud de explicaciones, nivel de abstracción) se definen por asignatura y por tipo de actividad, de acuerdo con el diseño curricular AI-Native de la Tecnicatura.


Desde el punto de vista del modelo C4, el T-IA-Cog se expresa como un componente lógico alojado en el contenedor ai-gateway, cuya configuración concreta puede variar entre cátedras y cohortes, pero cuya función estructural permanece estable: asegurar que la IA opere como tutor cognitivo alineado con los objetivos formativos y las políticas de gobernanza.
6.6.4. Ejemplo operativo en una actividad de programación
Para ilustrar el funcionamiento del T-IA-Cog, puede considerarse una actividad típica de una asignatura de Programación II:
Situación inicial
 En Moodle se publica un trabajo práctico donde el estudiante debe implementar una estructura de datos y un conjunto de operaciones básicas. El estudiante accede a la actividad y, mediante la integración LTI, se establece el contexto en el ai-gateway.


Primer intercambio
 El estudiante ingresa un prompt del tipo:
 “No entiendo cómo implementar esta cola con arreglos. ¿Me podés dar el código completo?”
 El módulo IPC clasifica la consulta como delegación total y activa el modo T-IA-Cog con política de alta exigencia de explicitación.


Intervención del tutor
 En lugar de devolver código, el T-IA-Cog responde:


pidiendo al estudiante que explique qué entiende por “cola” (operaciones, invariantes),


solicitando que esboce en pseudocódigo cómo imagina el encolado y el desencolado,


ofreciendo, si es necesario, un diagrama conceptual o una explicación de alto nivel sobre la estructura.


Evolución del razonamiento
 A medida que el estudiante responde, el tutor:


detecta conceptos correctos e incorrectos,


propone contraejemplos,


sugiere pruebas simples sobre casos de borde,


pide que el estudiante anticipe el comportamiento de su propia implementación.


Registro y evaluación posterior
 Todo el intercambio (prompts, respuestas, cambios de idea, correcciones) se registra en N4 y luego puede ser:


analizado por el docente para fines de evaluación,


utilizado como evidencia del desarrollo de competencias de razonamiento y autorregulación,


incorporado en informes agregados para instancias de gestión académica y calidad.


Este ejemplo muestra cómo el T-IA-Cog desplaza la interacción desde “pedir código” hacia “elaborar y justificar un razonamiento”, en coherencia con el planteo de la tesis.
6.6.5. Implicancias para evaluación y gobernanza
El submodelo T-IA-Cog tiene implicancias directas en dos planos críticos para la acreditación y el control de calidad:
Evaluación AI-Native basada en procesos
 Al estructurar la interacción como tutoría cognitiva y no como provisión de soluciones, el T-IA-Cog:


genera evidencias ricas del proceso de pensamiento del estudiante,


facilita la aplicación de rúbricas centradas en razonamiento, auditoría y metacognición,


contribuye a mitigar la pérdida de validez de los instrumentos evaluativos tradicionales en contextos con IA generativa.


Gobernanza y resguardo de la integridad académica
 Al operar bajo las restricciones del módulo de Gobernanza, Seguridad y Riesgo (GSR) y en articulación con políticas institucionales (UNESCO, 2021; ISO/IEC 23894, 2023; IEEE, 2019), el T-IA-Cog:


limita la posibilidad de usos indebidos de la IA (por ejemplo, generación encubierta de soluciones completas),


hace explícitas las condiciones bajo las cuales la IA puede intervenir en el aprendizaje,


permite reconstruir, ante eventuales controversias, la trayectoria de interacción entre estudiante e IA en una actividad específica.


En conjunto, el T-IA-Cog constituye el primer submodelo operativo que materializa, en el plano micro de las interacciones didácticas, los principios del modelo AI-Native: razonamiento híbrido, evaluación procesual, trazabilidad cognitiva y gobernanza integrada. Los submodelos restantes —evaluador IA de procesos, simuladores de roles profesionales, analista de riesgo cognitivo, agente de gobernanza y trazabilidad N4— se apoyan en esta misma lógica, extendiéndola a otras funciones del ecosistema formativo.

La literatura en IA generativa describe funciones aisladas (explicar código, generar funciones, corregir errores), pero no existe ningún marco que articule estos comportamientos como submodelos pedagógicos, cognitivos e institucionales coherentes. El aporte original de esta tesis consiste en:
Definir submodelos IA específicos para educación superior en programación.
Anclarlos en una infraestructura arquitectónica con gobernanza y trazabilidad.
Integrarlos en procesos cognitivos y pedagógicos reproducibles y evaluables.
Convertir la IA en un actor pedagógico estructural, no en una herramienta optativa.
Los siguientes submodelos representan la materialización operativa del razonamiento asistido–auditado.

6.7. Submodelo 2 — Evaluador IA de Procesos Cognitivos (E-IA-Proc)
El segundo submodelo operativo del ecosistema AI-Native es el Evaluador IA de Procesos Cognitivos (E-IA-Proc). Mientras que el T-IA-Cog actúa durante la resolución de actividades asistiendo y organizando el razonamiento, el E-IA-Proc interviene después o durante la producción del estudiante con una función distinta: analizar, reconstruir y evaluar el proceso cognitivo híbrido humano–IA que condujo a una solución técnica.
Su propósito no es calificar automáticamente ni reemplazar al docente, sino producir un análisis estructurado, basado en trazabilidad cognitiva N4, que permita verificar la autenticidad del razonamiento, la validez epistémica de las decisiones y el nivel de competencia alcanzado por el estudiante. Este enfoque responde directamente a las limitaciones de los dispositivos evaluativos tradicionales en contextos con IA generativa (ACM/IEEE-CS, 2023; Denny et al., 2024), y se alinea con la conceptualización doctoral del razonamiento asistido–auditado.

6.7.1. Fundamentación epistemológica y pedagógica
La creación del E-IA-Proc se justifica desde tres perspectivas críticas:
a) Epistemología de la programación en entornos con IA generativa
En línea con el Capítulo 2, la validez del aprendizaje no reside ya en el producto final —que puede ser generado íntegramente por un LLM— sino en la autenticidad del proceso cognitivo: comprensión, descomposición del problema, evaluación de alternativas, auditoría crítica de propuestas de la IA y toma de decisiones justificadas. El E-IA-Proc formaliza este enfoque epistémico.
b) Cognición distribuida y reconstrucción de procesos
Desde la teoría de la cognición distribuida (Hutchins, 1995; Hollan et al., 2000), el razonamiento emerge de la interacción entre humano, IA y artefactos. El E-IA-Proc funciona como una herramienta institucional de reconstrucción cognitiva, capaz de analizar patrones de interacción, secuencias de pensamiento y señales de delegación excesiva o razonamiento irreflexivo.
c) Evaluación formativa basada en evidencia procesual
El evaluador traduce los principios del modelo AI-Native en procedimientos concretos: genera informes estructurados, identifica fortalezas y debilidades en el razonamiento, y retroalimenta al estudiante y al docente con información accionable. Este enfoque retoma las conclusiones del estado del arte: la evaluación auténtica requiere centrarse en procesos (Denny et al., 2024; Franklin, 2025).

6.7.2. Funciones principales del E-IA-Proc
El submodelo cumple un conjunto de funciones expertas, todas orientadas a la evaluación del razonamiento y no al producto final del código:
1. Análisis de razonamiento
El E-IA-Proc examina:
la secuencia de prompts,


las alternativas evaluadas por el estudiante,


la coherencia entre decisiones y justificaciones,


la correspondencia entre la versión final del código y las revisiones intermedias.


A partir de estas trazas, el evaluador reconstruye el “camino cognitivo” seguido por el estudiante.
2. Detección de errores conceptuales y epistemológicos
El evaluador identifica:
confusiones de paradigmas,


fallas de abstracción,


razonamientos circulares,


errores algorítmicos no detectados por el estudiante,


aceptaciones acríticas de salidas de la IA.


Estas señales permiten evaluar profundidad de comprensión y calidad del proceso.
3. Evaluación de autorregulación (Zimmerman, 2002)
El E-IA-Proc analiza:
planificación del trabajo,


monitoreo de decisiones,


revisión crítica de errores,


capacidad de autoexplicación,


ajuste de estrategias.


Esto habilita una evaluación formativa más rica que la mera corrección de código.
4. Comparación y coherencia evolutiva del código vía Git
Mediante la integración con el repositorio institucional:
revisa commits,


detecta saltos abruptos incompatibles con razonamiento humano,


identifica patrones sospechosos de dependencia excesiva de la IA,


vincula cada cambio con sus correspondientes trazas N4.


Esta integración convierte a Git en un instrumento evaluativo cognitivo y no sólo técnico.
5. Generación del Informe de Evaluación Cognitiva (IEC)
El producto final del E-IA-Proc es un informe estructurado, que incluye:
mapa de razonamiento humano–IA,


análisis de decisiones,


evaluación de auditoría de IA,


riesgos cognitivos detectados,


fortalezas formativas,


puntos de mejora,


recomendaciones para el docente.


Este informe se convierte en insumo clave para la evaluación sumativa y para la retroalimentación institucional.

6.7.3. Funciones que NO cumple el Evaluador IA
Para cumplir estándares éticos y mantener la responsabilidad humana (UNESCO, 2021; IEEE, 2019), el E-IA-Proc tiene delimitaciones explícitas:
no asigna notas,


no aprueba ni desaprueba,


no realiza juicios disciplinarios,


no reemplaza la autoridad evaluadora del docente,


no corrige código automáticamente,


no sanciona casos de integridad académica.


Su rol es estrictamente analítico, formativo y de apoyo experto.

6.7.4. Arquitectura interna dentro del ai-gateway
El E-IA-Proc corresponde a un modo especializado del Motor de Razonamiento Cognitivo-Pedagógico (CRPE) y se articula con varios componentes clave:
C2 — Ingesta y Comprensión del Prompt (IPC)
Clasifica el tipo de interacción e identifica el conjunto de trazas que deberán ser analizadas.
C4 — Gobernanza, Seguridad y Riesgo (GSR)
Evalúa:
riesgo cognitivo,


uso indebido de IA,


señales de dependencia,


coherencia con políticas institucionales.


Incorpora estándares ISO/IEC 23894 (gestión de riesgo en IA).
C6 — Trazabilidad Cognitiva N4
Accede a:
prompts,


respuestas,


versiones intermedias de código,


decisiones razonadas,


patrones de interacción humano–IA.


Es el insumo principal del análisis del E-IA-Proc.
C7 — Integración con Git / n8n / Moodle
Permite:
correlación entre commits y razonamiento,


ejecución de flujos de revisión automática (n8n),


generación de reportes en Moodle.


En conjunto, estos componentes permiten reconstruir evidencia cognitiva con precisión institucional.

6.7.5. Ejemplo operativo del E-IA-Proc
Para ilustrar su funcionamiento:
Actividad: Implementación de un algoritmo de ordenamiento y pruebas unitarias.
Caso:
 El estudiante presenta un código final correcto, pero la base N4 revela:
prompts iniciales solicitando soluciones completas,


una propuesta de la IA aceptada sin revisión,


ausencia de pruebas propias,


un commit inicial masivo sin cambios incrementales.


Operación del E-IA-Proc:
detecta delegación total incompatible con competencias esperadas,


identifica ausencia de verificación propia,


señala falta de razonamiento explícito,


evalúa la interacción como cognitivamente superficial,


produce un informe IEC para el docente.


El docente, con esta evidencia, puede orientar la retroalimentación y decidir la acreditación con criterios más sólidos que el simple funcionamiento del código.

6.7.6. Implicancias para evaluación, gobernanza y aseguramiento de calidad
El E-IA-Proc fortalece tres ejes críticos:
1. Validez evaluativa
Permite evaluar aquello que la IA generativa no puede suplir:
 razonamiento, criterio, auditoría, justificación, metacognición.
2. Integridad académica
El análisis de patrones de interacción y evoluciones del código permite:
detectar uso indebido,


evitar automatización encubierta de actividades,


sustentar decisiones disciplinarias con evidencia robusta.


3. Gobernanza institucional
Genera métricas que alimentan:
tableros de calidad de la carrera,


reportes a secretarías académicas,


procesos de autoevaluación para acreditación,


auditorías de cumplimiento de principios éticos (UNESCO, OECD, IEEE).


Con estas funciones, el E-IA-Proc constituye el núcleo evaluativo del modelo AI-Native, garantizando que la integración de IA generativa fortalezca —y no erosione— los estándares académicos.
6.8. Submodelo 3 — Simuladores Profesionales IA (S-IA-X)
(Versión doctoral — alineado con estándares CONEAU y marcos de cognición situada, simulación educativa y razonamiento híbrido humano–IA)
El tercer submodelo del ecosistema AI-Native, denominado S-IA-X, agrupa un conjunto de agentes de simulación avanzada diseñados para recrear roles, escenarios y dinámicas profesionales auténticas en entornos de programación, ingeniería de software y DevSecOps. A diferencia del T-IA-Cog (orientado a tutoría cognitiva) y del E-IA-Proc (orientado a evaluación procesual), los simuladores cumplen una función situada, contextual y profesionalizante: permiten que el estudiante experimente, bajo supervisión y trazabilidad, situaciones reales del campo laboral, habitualmente inaccesibles en la educación tradicional.
Los S-IA-X materializan la premisa del modelo AI-Native: la formación profesional debe incluir la interacción con agentes de IA que ocupan roles reales de la industria, tal como ocurre en los equipos modernos de desarrollo, donde la IA participa en análisis, diseño, testeo, seguridad y planificación.

6.8.1. Fundamentación teórica y cognitiva del uso de simulaciones IA
El diseño de los S-IA-X se apoya en tres marcos teóricos fundamentales:
a) Cognición situada y distribuida
(Referencias: Hutchins, 1995; Hollan et al., 2000)
Los simuladores modelan contextos completos —no sólo tareas aisladas— permitiendo que el razonamiento del estudiante se distribuya entre:
artefactos (código, repositorios, pipelines),


agentes IA,


restricciones del entorno,


retroalimentación automática y docente.


Esto posiciona a los simuladores como componentes cognitivos activos de la ecología formativa.
b) Simulación profesional auténtica
(Referencias: Lave & Wenger, aprendizaje situado; teoría de práctica deliberada)
La investigación en educación en ingeniería demuestra que las simulaciones:
aumentan transferencia,


fortalecen toma de decisiones,


consolidan pensamiento holístico,


permiten experimentar riesgo sin consecuencias reales.


Los S-IA-X trasladan este enfoque al campo del software.
c) Evaluación de desempeño en ecosistemas híbridos
Los simuladores generan trazas completas de interacción humano–IA, lo que:
habilita análisis longitudinal de competencias,


minimiza la subjetividad evaluativa,


permite al docente evaluar desempeño profesional basado en evidencia.



6.8.2. Definición general del submodelo S-IA-X
El submodelo S-IA-X está compuesto por una serie de agentes cognitivo-profesionales que pueden asumir diferentes roles institucionalizados de la industria del software. Cada simulador cumple funciones específicas, tiene reglas pedagógicas propias y opera bajo control del módulo de Gobernanza (GSR) del ai-gateway.
Los simuladores cumplen cinco funciones estructurales:
Crear condiciones situadas de práctica profesional.


Desarrollar competencias transversales (comunicación, análisis de requisitos, gestión de riesgo, liderazgo técnico).


Entrenar al estudiante en interacción humano–IA contextualizada.


Modelar decisiones profesionales con trazabilidad N4.


Generar evidencia para evaluación formativa y acreditación.



6.8.3. Arquitectura general del submodelo S-IA-X
Cada simulador incorpora:
Módulo de contexto profesional (CP-X)
 Define el entorno: proyecto, restricciones, roles, objetivos, riesgos.


Módulo de diálogo y negociación (DN-X)
 Gestiona interacciones, repreguntas, cambios de requisitos.


Módulo de evaluación situacional (ES-X)
 Produce recomendaciones sobre desempeño contextual.


Módulo de consistencia técnica (CT-X)
 Verifica si las respuestas del estudiante respetan estándares del rol simulado.


Módulo de gobernanza contextual (GC-X)
 Alinea cada simulación con criterios éticos, normativos y de responsabilidad profesional.


Todos los simuladores registran prompts, interacciones, decisiones, desviaciones y razonamientos en N4.

6.8.4. Catálogo de Simuladores del submodelo S-IA-X
A continuación se presentan los simuladores principales contemplados en la arquitectura AI-Native.

6.8.4.1. Simulador Product Owner (PO-IA)
Rol en la industria: prioriza backlog, define criterios de aceptación, gestiona cambios de alcance.
 Propósito formativo: entrenar comunicación, negociación, toma de requisitos y justificación técnica.
Funciones específicas
Solicita criterios de aceptación claros.


Evalúa si la propuesta técnica satisface necesidades del cliente.


Introduce ambigüedades realistas para evaluar resolución de problemas.


Requiere al estudiante justificar decisiones de diseño.


Competencias evaluadas
Análisis de requisitos.


Comunicación técnica.


Priorización y criterio.


Justificaciones epistémicas.


Trazabilidad generada
registros de negociación,


decisiones justificadas,


cambios de alcance,


análisis comparativos entre alternativas.



6.8.4.2. Simulador Scrum Master (SM-IA)
Rol en la industria: coordina ceremonias ágiles, gestiona impedimentos, facilita retrospectivas.
 Propósito: desarrollar competencias de trabajo en equipo y metodologías ágiles.
Funciones específicas
Simula daily meetings con repreguntas.


Detecta impedimentos en el razonamiento del estudiante.


Propone reflexiones sobre proceso, deuda técnica y flujo de trabajo.


Evalúa capacidad de planificación.


Competencias evaluadas
Gestión del proceso.


Pensamiento iterativo.


Reconocimiento de impedimentos.



6.8.4.3. Simulador de Entrevista Técnica Senior (IT-IA)
Rol: entrevistador técnico experto.
 Propósito: preparar al estudiante para evaluaciones reales de la industria.
Funciones específicas
Revisa fundamentos algorítmicos.


Formula preguntas adaptativas según trazas previas N4.


Detecta razonamiento superficial.


Evalúa claridad conceptual y profundidad del pensamiento.


Competencias evaluadas
Dominio conceptual.


Pensamiento en voz alta.


Capacidad explicativa y argumental.



6.8.4.4. Laboratorio de Incidentes y Operaciones (IR-IA)
Rol: simula incidentes reales de producción y entornos DevOps/DevSecOps.
 Propósito: entrenar respuesta técnica bajo presión y toma de decisiones crítica.
Escenarios modelados
caída de APIs,


fallos de concurrencia,


deadlocks,


vulnerabilidades XSS/SQLi,


degradación de servicios.


Competencias evaluadas
pensamiento crítico,


gestión de incidentes,


detección de causa raíz,


priorización de riesgos.



6.8.4.5. Cliente Simulado IA (CX-IA)
Rol: representa clientes con distintos perfiles comunicacionales.
 Propósito: entrenar manejo de requisitos ambiguos y habilidades blandas.
Funciones específicas
Emite pedidos contradictorios o incompletos.


Solicita aclaraciones.


Evalúa calidad comunicacional del estudiante.



6.8.4.6. Simulador DevSecOps (DSO-IA)
Rol: actúa como analista de seguridad y operaciones.
 Propósito: entrenar prácticas seguras, auditoría y pensamiento de riesgo.
Funciones específicas
analiza dependencias vulnerables,


detecta configuraciones inseguras,


propone parches,


evalúa pipelines CI/CD,


genera amenazas simuladas.



6.8.5. Integración del submodelo S-IA-X con el ai-gateway
El S-IA-X funciona como modo operativo del CRPE, activado según:
tipo de actividad,


nivel del estudiante,


objetivos curriculares,


políticas de riesgo (ISO/IEC 23894).


El ai-gateway determina:
qué simulador invocar,


qué restricciones aplicar,


qué trazabilidad capturar,


qué alertas generar (p. ej., dependencia cognitiva, delegación total, razonamiento superficial).



6.8.6. Ejemplo operativo del S-IA-X
Actividad: Diseño de un servicio REST para un sistema de turnos.
 Simulador activado: PO-IA.
Flujo real:
El PO-IA plantea un requisito ambiguo.


El estudiante solicita aclaraciones.


El simulador introduce restricciones nuevas (pico de demanda, compatibilidad móvil...).


El estudiante propone un diseño y justifica decisiones.


El simulador evalúa madurez del criterio, propone riesgos.


N4 registra todo el razonamiento.


Resultado:
 El docente obtiene un mapa procesual profesionalizante que no es posible con actividades tradicionales.

6.8.7. Aportes específicos del submodelo S-IA-X a la calidad académica
Autenticidad profesional: acercamiento real a prácticas de la industria.


Desarrollo de competencias transversales difícilmente evaluables con métodos clásicos.


Escalabilidad institucional: permite simular cientos de escenarios sin sobrecargar al cuerpo docente.


Evidencia evaluativa robusta: N4 registra decisiones, razonamientos y patrones profesionales.


Alineación con estándares internacionales (ACM, IEEE, UNESCO, ISO/IEC).


El submodelo S-IA-X convierte la carrera en un entorno profesional auténtico, donde el estudiante desarrolla competencias técnicas y situadas, en interacción con agentes IA especializados.


6.9. Submodelo 4 — Analista de Riesgo Cognitivo y Ético (AR-IA)
(Versión doctoral — 100% alineada con la arquitectura AI-Native, el ai-gateway y los estándares UNESCO–OECD–ISO/IEC)
El cuarto submodelo del ecosistema AI-Native, denominado AR-IA, constituye el agente responsable de supervisar, detectar y clasificar riesgos cognitivos, éticos y epistémicos derivados de la interacción humano–IA durante actividades de programación, simulaciones y prácticas profesionalizantes.
 Este submodelo resulta crítico para garantizar:
la calidad cognitiva del aprendizaje,


la integridad epistémica de la producción,


la gobernanza operativa del uso de IA, y


la protección institucional frente a riesgos de uso indebido o delegación excesiva.


El AR-IA es uno de los aportes más originales y diferenciadores de esta tesis: no existe en la literatura un agente IA diseñado explícitamente para vigilar el riesgo cognitivo del estudiante y el riesgo ético del proceso educativo.

6.9.1. Fundamentación cognitiva, ética y normativa
El diseño del AR-IA se fundamenta en tres cuerpos teóricos y normativos:

a) Riesgo cognitivo en sistemas híbridos humano–IA
Basado en:
Cognición distribuida (Hutchins, 1995)


Cognición extendida (Clark & Chalmers, 1998)


Teoría de carga cognitiva (Sweller, 1988)


Autorregulación del aprendizaje (Zimmerman, 2002)


El AR-IA detecta situaciones donde:
el estudiante delega excesivamente en la IA,


existe pérdida de agencia cognitiva,


aparece razonamiento superficial,


se manifiesta dependencia cognitiva,


hay ausencia de planificación y metacognición,


o se observan indicadores de esfuerzo cognitivo insuficiente.


Estos fenómenos están ampliamente documentados en el estado del arte (Ma, 2023; Denny et al., 2024).

b) Marcos éticos y de gobernanza IA
El AR-IA implementa normas y lineamientos de:
UNESCO (2021) — Ética en IA para la Educación


OECD AI Principles (2019)


IEEE Ethically Aligned Design (2019)


ISO/IEC 23894:2023 — Gestión del riesgo en IA


ISO/IEC 42001:2023 — Sistema de Gestión para IA


Desde estos marcos, el AR-IA vela por principios de:
justicia,


transparencia,


proporcionalidad,


rendición de cuentas,


trazabilidad,


uso responsable de agentes generativos.



c) Integridad académica y trazabilidad
Tal como se analiza en el Capítulo 3, la IA generativa tensiona profundamente:
el concepto de autoría,


la relación entre proceso y producto,


la validez de la evidencia de aprendizaje.


El AR-IA funciona como mecanismo institucional de preservación de la integridad académica, trasladando la responsabilidad desde el castigo ex post (modelo clásico) hacia la detección temprana de patrones de riesgo y la corrección pedagógica preventiva.

6.9.2. Definición general del submodelo AR-IA
El AR-IA es un agente de supervisión cognitivo-ético integrado en el ai-gateway, cuya función consiste en:
Identificar, clasificar y reportar riesgos cognitivos, éticos, epistémicos y de gobernanza presentes en la interacción humano–IA, con el fin de orientar intervenciones pedagógicas, ajustar modos de tutoría y generar alertas institucionales.
Este submodelo opera en paralelo a la actividad del estudiante, del T-IA-Cog y de los simuladores S-IA-X.

6.9.3. Tipología de riesgos monitorizados por el AR-IA
Los riesgos que detecta el AR-IA se clasifican en cinco dimensiones:

1. Riesgos Cognitivos (RC)
Incluyen:
Delegación total (la IA resuelve todo el problema).


Respuestas sin razonamiento propio.


Copy-adoption: adopción irreflexiva de código generado.


Ausencia de verificación o testing.


Incapacidad de explicar la propia solución.


Búsqueda excesiva de atajos.


Evidencias:
 prompts pobres, ausencia de detalle, nula iteración, razonamiento superficial, bajo tiempo entre ciclos.

2. Riesgos Epistémicos (RE)
Asociados a:
aceptación de “errores silenciosos”,


dependencia del patrón estadístico sobre la comprensión conceptual,


justificaciones simuladas,


contradicciones no detectadas,


decisiones técnicas no fundamentadas.



3. Riesgos Éticos (RÉ)
Incluyen:
uso indebido de IA para evadir aprendizaje,


manipulación del sistema,


revelación involuntaria de datos sensibles,


generación de contenido inapropiado o inseguro.



4. Riesgos del Proceso de Aprendizaje (RP)
Asociados a:
falta de autorregulación,


dependencia cognitiva,


estancamiento,


frustración no detectada,


sobrecarga cognitiva.



5. Riesgos de Gobernanza (RG)
Alineados con ISO/IEC 23894:
violación de políticas institucionales de IA,


uso fuera de parámetros autorizados,


trazabilidad incompleta,


actividad anómala del modelo.



6.9.4. Arquitectura interna del submodelo AR-IA
El AR-IA se compone de cuatro módulos funcionales, cada uno con responsabilidades técnicas, cognitivas, éticas y normativas:

M1. Detector de Patrones de Riesgo Cognitivo (DPRC)
Analiza:
forma, frecuencia y contenido de prompts,


profundidad del razonamiento,


proporción entre acción humana y acción IA,


iteraciones sin justificación,


ausencia de validación.


Emplea heurísticas + modelos estadísticos + reglas institucionales.

M2. Analizador Ético-Normativo (AEN)
Verifica cumplimiento de:
políticas institucionales de IA,


criterios de integridad académica,


estándares éticos UNESCO–OECD–IEEE.


Identifica:
uso indebido,


riesgos de seguridad,


violaciones de privacidad.



M3. Evaluador de Riesgo Cognitivo-Epistémico (ERCE)
Evalúa la salud cognitiva del proceso:
consistencia interna,


calidad argumental,


explicación auténtica,


presencia de razonamiento inventado,


“inflación explicativa” típica de LLMs.



M4. Generador de Alertas y Recomendaciones (GAR)
Produce tres tipos de intervenciones:
alertas al docente,


mensajes directivos al estudiante,


ajustes automáticos en los submodelos
 (p. ej., activar modo socrático, aumentar dificultad, bloquear soluciones completas).


Todas las alertas se registran en N4.

6.9.5. Integración del AR-IA en la arquitectura AI-Native
El AR-IA se integra en el ai-gateway con funciones transversales:
monitoreo en tiempo real,


clasificación de riesgo por niveles (bajo–medio–alto),


sugerencias al Motor Cognitivo-Pedagógico (CRPE),


activación de simuladores especializados,


registro exhaustivo en la base N4.


Además:
interviene en las decisiones del LLM-Orchestrator,


aplica restricciones pedagógicas (p. ej., bloquear generación directa de código),


adapta el modo de tutoría del T-IA-Cog.



6.9.6. Ejemplo operativo del AR-IA
Caso:
 El estudiante solicita directamente:
“Dame la solución completa del ejercicio.”
El AR-IA detecta:
riesgo cognitivo alto (delegación total),


ausencia de razonamiento,


violación de reglas de uso.


Acciones del AR-IA:
Bloquea la entrega directa de la solución.


Responde:
 “Debes explicitar tu razonamiento inicial y las restricciones del problema. ¿Qué alternativas consideraste hasta ahora?”


Notifica al docente (“alerta amarilla”).


Registra evidencia en N4.


Solicita al T-IA-Cog activar modo socrático.



6.9.7. Aportes del AR-IA a la calidad académica
Este submodelo fortalece cinco dimensiones de calidad requeridas por CONEAU:
1. Validez del aprendizaje
Garantiza que el estudiante razone, no sólo “genere código”.
2. Integridad académica estructural
La autoría y el proceso cognitivo quedan trazados y auditables.
3. Calidad y seguridad del ecosistema IA
Mitiga riesgos técnicos y éticos.
4. Protección de la institución
Reduce riesgos en procesos de evaluación, acreditación e integridad del título.
5. Generación de evidencia para mejora continua
Los datos de riesgo alimentan indicadores institucionales.

6.9.8. Síntesis del submodelo AR-IA
El AR-IA convierte al ecosistema AI-Native en un entorno seguro, éticamente gobernado y cognitivamente responsable, asegurando que:
el estudiante aprende con IA,


pero no a pesar de la IA,


y nunca en lugar de la IA.


Es uno de los pilares que hacen que la Tecnicatura sea la primera carrera con gobernanza cognitiva integrada en el sistema universitario argentino.

6.10. Submodelo 5 — Agente IA de Gobernanza Institucional (GOV-IA)
(Versión doctoral — exhaustiva y alineada con UNESCO, OECD, IEEE, ISO/IEC 42001 y 23894)
El submodelo GOV-IA constituye el agente encargado de operacionalizar la gobernanza institucional de la IA generativa en el ecosistema educativo, articulando políticas, lineamientos éticos, gestión del riesgo, cumplimiento normativo y mecanismos de auditoría.
 En contraste con sistemas tradicionales en los que la gobernanza se reduce a documentos declarativos, el GOV-IA implementa la gobernanza como proceso activo, automatizado y verificable, integrado de manera estructural en la arquitectura AI-Native.
Este agente es fundamental para asegurar que la implementación del modelo no sólo sea pedagógica y técnicamente consistente, sino también regulatoriamente conforme, éticamente responsable y auditable según estándares de acreditación.

6.10.1. Fundamentación ética, normativa y de gobernanza
El GOV-IA se fundamenta en cinco marcos internacionales de referencia:

a) UNESCO (2021). Recomendación sobre la Ética de la IA
Proporciona principios rectores para IA en educación:
equidad,


inclusión,


transparencia,


rendición de cuentas,


trazabilidad,


proporcionalidad.


El GOV-IA implementa estos principios en cada interacción humano–IA.

b) OECD AI Principles (2019)
Define lineamientos para IA confiable, incluyendo:
supervisión humana,


solidez técnica,


seguridad,


gobernanza del ciclo de vida,


gestión del riesgo.


El agente los transforma en reglas operativas dentro del ai-gateway.

c) IEEE Ethically Aligned Design (2019)
Introduce los principios de:
bienestar humano,


derechos individuales,


responsabilidad profesional,


transparencia explicable.


El GOV-IA los traduce en restricciones activas y mecanismos de auditoría.

d) ISO/IEC 23894:2023 (Risk Management in AI)
Organiza el riesgo de IA en:
riesgo técnico,


riesgo cognitivo,


riesgo ético,


riesgo organizacional,


riesgo de cumplimiento.


Este estándar es la base para la taxonomía de riesgos y la clasificación automatizada.

e) ISO/IEC 42001:2023 (AI Management System — AIMS)
Proporciona el marco para implementar un Sistema de Gestión de IA institucional.
El GOV-IA es el módulo que permite transformar el ecosistema AI-Native en un AIMS operativo.

6.10.2. Función general del submodelo GOV-IA
El GOV-IA es el agente que garantiza que todas las interacciones humano–IA del ecosistema AI-Native cumplan con las políticas institucionales, los estándares éticos y las normativas de seguridad y trazabilidad.
Su propósito es doble:
1. Gobernanza operativa:
Asegura cumplimiento, auditabilidad y seguridad en tiempo real.
2. Gobernanza estratégica:
Genera evidencia, reportes e indicadores para la toma de decisiones institucional, comisiones de calidad, procesos de acreditación y gestión académica.
Ningún modelo pedagógico basado en IA puede ser acreditado sin este bloque de gobernanza activa.

6.10.3. Dimensiones de gobernanza integradas por el GOV-IA
El GOV-IA opera sobre cuatro dimensiones institucionales:

A. Gobernanza Ética
Incluye:
detección de uso indebido,


clasificación de contenido inapropiado,


evaluación de sesgos del modelo,


identificación de posibles daños cognitivos o pedagógicos,


verificación del cumplimiento de principios UNESCO–IEEE–OECD.


Acciones concretas:
 bloqueo de respuestas peligrosas, corrección automática, activación del AR-IA.

B. Gobernanza del Riesgo
Basada en ISO/IEC 23894.
 El agente clasifica riesgos en cinco categorías:
Técnico


Cognitivo


Epistémico


Normativo


Organizacional


Genera un Risk Score para cada interacción y deriva alertas.

C. Gobernanza de Trazabilidad y Rendición de Cuentas
El GOV-IA garantiza:
trazabilidad completa de cada interacción,


registro en N4,


preservación de autoría,


evidencia para evaluación y acreditación,


auditabilidad post-mortem de actividades docentes y estudiantiles.



D. Gobernanza de Conformidad y Cumplimiento
Incluye:
cumplimiento de políticas institucionales de IA,


cumplimiento del Reglamento Académico,


protección de datos personales,


conformidad con GDPR/Argentina 25.326,


cumplimiento de normas UTN–SIED 2026.


Genera reportes para:
Secretaría Académica,


Área de Innovación Educativa,


Comisiones de Ética,


Comités de Calidad.



6.10.4. Arquitectura interna del submodelo GOV-IA
El GOV-IA consta de cinco módulos, cada uno con funciones específicas:

G1. Módulo de Políticas Institucionales (MPI)
Implementa las políticas de uso de IA definidas por UTN–FRM:
restricciones,


reglas,


permisos,


límites de acción.
 Define qué puede y qué no puede hacer la IA según:


asignatura,


cátedra,


docente,


actividad.



G2. Motor de Gestión del Riesgo (MGR)
Clasifica y cuantifica riesgos según ISO 23894.
 Trabaja en conjunto con el AR-IA:
detecta,


agrupa,


prioriza,


deriva intervenciones.


Produce un Risk Index para docentes y autoridades.

G3. Auditor IA de Cumplimiento (AIC)
Rol equivalente a “compliance officer” institucional.
 Supervisa:
integridad académica,


plagio algorítmico,


uso indebido de IA,


violaciones del currículo.



G4. Registro Normativo en N4 (RN-N4)
Todo evento de gobernanza queda trazado en N4, incluyendo:
conflictos,


excepciones,


decisiones,


intervenciones automáticas,


logs de riesgo.


Este historial es esencial para CONEAU.

G5. Generador de Reportes de Gobernanza (GRG)
Produce informes para:
docentes,


coordinación de carrera,


instancias institucionales,


procesos de acreditación.


Incluye:
estadísticas de riesgo,


problemas detectados,


patrones críticos,


indicadores longitudinales.



6.10.5. Integración del GOV-IA en la arquitectura AI-Native
El GOV-IA actúa como componente transversal del ai-gateway y de todo el ecosistema:
regula los submodelos
 (tutor, evaluador, simuladores, AR-IA);


modula el LLM-Orchestrator;


determina límites de acción de IA;


interviene en la dinámica N4;


genera evidencia para calificaciones y acreditación.


La arquitectura C4 lo reconoce como el eje de equilibrio entre innovación y seguridad.

6.10.6. Ejemplo operativo del GOV-IA
Situación:
 El estudiante utiliza IA para resolver un TP sin evidencia de razonamiento.
GOV-IA detecta:
Riesgo cognitivo alto (AR-IA).


Incumplimiento de política de IA (MPI).


Intento de eludir evaluación de proceso.


Acciones:
Bloqueo parcial de funcionamiento.


Solicitud de reexplicación del proceso.


Notificación al docente y a la coordinación.


Creación de un “caso de seguimiento”.


Registro completo en N4.



6.10.7. Aportes del submodelo GOV-IA a la calidad institucional
El GOV-IA contribuye directamente a:
1. Calidad académica (CONEAU)
Asegura evidencia válida y trazable del aprendizaje.
2. Gobernanza responsable de IA
Evita riesgos institucionales y protege la integridad académica.
3. Acreditación y auditorías
Proporciona informes automáticos para comités evaluadores.
4. Equilibrio entre innovación y seguridad
Garantiza que la IA sea útil sin comprometer calidad ni ética.
5. Transparencia y rendición de cuentas
Reduce incertidumbre y aumenta confianza institucional.

6.10.8. Síntesis del submodelo GOV-IA
El agente de gobernanza institucional convierte la arquitectura AI-Native en un ecosistema:
éticamente robusto,


normativamente conforme,


cognitivamente seguro,


institucionalmente defendible,


auditable por organismos externos,


alineado con estándares internacionales.


Es uno de los elementos que habilitan que la Tecnicatura Universitaria en Programación con IA Nativa sea acreditable, replicable y sostenible en el tiempo.
6.11. Submodelo 6 — Sistema N4 de Trazabilidad Cognitiva Institucional (TC-N4)
(Versión Doctoral Extendida – 10+ páginas)
El Sistema N4 de Trazabilidad Cognitiva Institucional constituye el componente más original y decisivo del modelo AI-Native. Representa el dispositivo operativo que permite registrar, reconstruir y analizar el proceso completo de razonamiento híbrido humano–IA, ofreciendo una evidencia evaluativa y académica sin precedentes en la educación superior.
Mientras que la mayor parte de la literatura sobre IA en educación se concentra en productos (código, respuestas, entregas), el submodelo N4 transforma el razonamiento —habitualmente invisible— en un objeto cognitivo auditable, capaz de sostener:
evaluación formativa y sumativa basada en procesos,


investigación educativa reproducible,


trazabilidad epistémica,


cumplimiento de estándares éticos y normativos,


acreditación y control de calidad institucional.


N4 se constituye así en la columna vertebral del ecosistema AI-Native, conectando arquitectura, gobernanza, tutoría, simulaciones, evaluación y gestión académica.

6.11.1. Fundamentación epistemológica y pedagógica
La necesidad del submodelo N4 surge de tres problemas estructurales —demostrados en Capítulos 2 y 3— que afectan a la formación universitaria en programación:
1. Invisibilidad del proceso cognitivo
El docente sólo ve el código final, pero no puede evaluar:
las decisiones,


el razonamiento,


los errores intermedios,


la auditoría realizada a la IA,


los cambios de estrategia,


el nivel de dependencia de la IA.


2. Invalidez de la evidencia tradicional
En presencia de IA generativa, el producto final ya no garantiza autoría ni aprendizaje.
3. Ausencia de mecanismos de trazabilidad
Ningún modelo actual captura sistemáticamente las interacciones humano–IA ni las reconstruye en términos evaluables.
El submodelo N4 resuelve estos problemas transformando el proceso en evidencia.

6.11.2. Conceptualización del sistema N4
El sistema N4 opera sobre cuatro niveles de trazabilidad, cada uno más profundo que el anterior:
N1 — Trazabilidad superficial
Registro de archivos, entregas, versión final del código.
N2 — Trazabilidad técnica
Evolución de commits, branches, tests automatizados.
N3 — Trazabilidad interaccional
Prompts, respuestas, reintentos, explicaciones parciales, logs de interacción.
N4 — Trazabilidad cognitiva completa (núcleo del modelo)
Reconstrucción semántica y estructural del razonamiento:
intención cognitiva,


decisiones y justificaciones,


alternativas descartadas,


cambios de estrategia,


auditorías realizadas por el estudiante,


evaluación del riesgo cognitivo,


intervención del tutor IA,


intervención docente,


cumplimiento normativo.


El nivel N4 constituye una matriz de pensamiento híbrido que permite evaluar lo que CONEAU denomina “evidencia auténtica del aprendizaje”.

6.11.3. Arquitectura interna del N4
El submodelo incluye siete módulos internos, cada uno con responsabilidades cognitivas, técnicas, pedagógicas y normativas:

M1. Módulo de Captura Multicanal (CM-N4)
Recolecta en tiempo real:
prompts enviados al ai-gateway,


respuestas generadas por IA,


iteraciones de refinamiento,


decisiones del estudiante,


intervenciones del tutor IA,


commits Git,


logs de n8n,


pruebas unitarias,


comentarios en Moodle.


La captura es sincronizada, automática y transparente, cumpliendo GDPR / Ley 25.326.

M2. Módulo de Análisis Cognitivo (AC-N4)
Clasifica cada evento según:
tipo de razonamiento (exploratorio, algorítmico, sintáctico, conceptual),


nivel de profundidad,


relación con la solución final,


evidencia de comprensión,


capacidad de auditoría,


grado de delegación a IA.


Utiliza heurísticas cognitivas basadas en:
Cognición distribuida (Hutchins, 1995),


Cognición extendida (Clark & Chalmers, 1998),


Carga cognitiva (Sweller, 1988),


Metacognición (Zimmerman, 2002).



M3. Módulo de Reconstrucción Temporal del Razonamiento (RTR-N4)
Ordena y reconstruye el proceso completo:
Pregunta inicial


Primera hipótesis


Exploración asistida por IA


Evaluación de alternativas


Auditoría del código IA


Correcciones sucesivas


Cambios de enfoque


Justificación final


Genera una línea de tiempo cognitiva fundamental para evaluación y acreditación.

M4. Módulo de Evaluación de Riesgo Cognitivo-Epistémico (RCE-N4)
Opera en conjunto con:
GOV-IA,


AR-IA,


Evaluador IA-Proc.


Clasifica riesgos como:
delegación indebida,


razonamiento superficial,


dependencia algorítmica,


falta de auditoría,


problemas éticos,


violaciones de normas institucionales.



M5. Módulo de Métricas Cognitivas y Pedagógicas (MCP-N4)
Genera indicadores avanzados, como:
Índice de Profundidad Cognitiva (IPC),


Índice de Autenticidad del Razonamiento (IAR),


Índice de Auditoría de IA (IAI),


Índice de Riesgo Epistémico (IRE),


Brecha entre razonamiento inicial y final,


Nivel de intervención docente e IA.


Estos indicadores son pioneros en el sistema universitario.

M6. Módulo de Integración Institucional (II-N4)
Integra N4 con:
Moodle (LTI 1.3),


Git,


n8n,


sistemas de evaluación,


paneles de calidad,


informes para acreditación.


Genera reportes automáticos para:
docentes,


coordinación,


Secretaría Académica,


áreas de calidad,


comisiones externas (CONEAU).



M7. Módulo de Evidencia Evaluativa (EE-N4)
Produce:
Informe de Razonamiento Cognitivo (IRC),


Informe de Auditoría Híbrida (IAH),


Informe de Riesgo Cognitivo (IRC-2),


Expediente evaluativo del estudiante,


Evidencia para evaluación sumativa,


Evidencia para prácticas profesionalizantes,


Evidencia para acreditación.



6.11.4. Integración del N4 con los submodelos AI-Native
N4 no es un componente aislado:
 Es el centro de gravedad cognitivo y evaluativo del ecosistema.
Se integra con:
el Tutor IA (T-IA-Cog),


el Evaluador IA (E-IA-Proc),


los Simuladores (S-IA-X),


el Analista de Riesgo Cognitivo (AR-IA),


el Agente de Gobernanza Institucional (GOV-IA),


el LLM-Orchestrator,


la arquitectura C4,


el ai-gateway,


el plan de estudios y las rúbricas AI-Native.


El sistema completo gira alrededor del N4.

6.11.5. Ejemplo operativo del N4 (Caso realista)
Actividad: TP 3 – Implementar API REST con autenticación básica.
Fase 1 — Prompt inicial
El estudiante formula una pregunta ambigua → N4 detecta baja claridad cognitiva.
Fase 2 — Tutoría
El T-IA-Cog interviene con preguntas socráticas → se registra todo en N4.
Fase 3 — Generación IA
IA propone una solución incompleta → se registra.
Fase 4 — Auditoría
El estudiante corrige partes → N4 registra razonamiento auténtico.
Fase 5 — Git
Commit documentado → integrado automáticamente en N4.
Fase 6 — Riesgo cognitivo
AR-IA detecta delegación parcial → riesgo moderado.
Fase 7 — Evaluación
E-IA-Proc genera informe en base N4.
Fase 8 — Evidencia
N4 produce el Informe de Razonamiento Cognitivo (IRC) para el docente.

6.11.6. Aportes institucionales del N4
Este submodelo permite:
1. Validez evaluativa
Se puede evaluar lo que el estudiante pensó, no sólo lo que entregó.
2. Transparencia y auditabilidad
Cada decisión puede ser revisada en auditorías internas y externas.
3. Acreditación CONEAU
Brinda evidencia empírica para los estándares de calidad educativa.
4. Ética y gobernanza
Permite implementar principios UNESCO–OECD–ISO.
5. Mejora continua
Genera datos longitudinales para la gestión institucional.
6. Investigación educativa
N4 es una plataforma para investigación en cognición asistida por IA.

6.11.7. Síntesis del submodelo N4
El sistema N4 es el mayor aporte original de esta tesis doctoral.
 Convierte el aprendizaje en programación asistida por IA en un proceso:
visible,


trazable,


auditable,


evaluable,


éticamente gobernado,


institucionalizable.


Permite superar la crisis de validez evaluativa provocada por la IA generativa y ofrece un camino para que la educación superior pueda integrar IA sin perder calidad ni rigor.
6.12. Síntesis del Bloque de Submodelos del Modelo AI-Native
(Versión Doctoral – 6 a 8 páginas)
El conjunto de submodelos AI-Native constituye la dimensión operativa, cognitiva, pedagógica e institucional del ecosistema definido en el Capítulo 6. Si la arquitectura C4 provee la infraestructura técnica del sistema, los submodelos representan las formas de agencia de la IA dentro de ese ecosistema, explícitamente reguladas, gobernadas y orientadas a finalidades educativas verificables.
A diferencia de aproximaciones instrumentales —centradas en herramientas, plugins o funcionalidades aisladas— los submodelos AI-Native articulan funciones cognitivas, pedagógicas, tecnológicas y normativas dentro de un marco coherente, reproducible y evaluable. Este enfoque constituye uno de los aportes originales más significativos de la tesis, pues convierte a la IA en un actor pedagógico estructural, no en un accesorio opcional.
Los submodelos son seis:
Tutor Disciplinar Cognitivo (T-IA-Cog)


Evaluador Procesual y Auditivo (E-IA-Proc)


Simuladores Avanzados (S-IA-X)


Analista de Riesgo Cognitivo y Ético (AR-IA)


Agente de Gobernanza Institucional (GOV-IA)


Sistema de Trazabilidad Cognitiva Institucional N4 (TC-N4)


Cada submodelo contribuye a resolver una dimensión crítica del problema doctoral planteado en el Capítulo 1. Juntos conforman una maquinaria cognitiva híbrida orientada a garantizar la calidad del aprendizaje en programación en tiempos de IA generativa.

6.12.1. Coherencia epistemológica del bloque
Los submodelos se sustentan en cuatro marcos teóricos:
Cognición distribuida (Hutchins, 1995): el razonamiento emerge del sistema humano–IA, no del individuo aislado.


Cognición extendida (Clark & Chalmers, 1998): los sistemas generativos funcionan como extensiones materiales de la mente humana.


Teoría de la carga cognitiva (Sweller, 1988): la IA redistribuye cargas de producción y verificación, alterando la arquitectura cognitiva del aprendizaje.


Metacognición autorregulada (Zimmerman, 2002): el estudiante debe dirigir, monitorear y evaluar su propio proceso en interacción con la IA.


Los seis submodelos operativizan estos principios en estructuras, flujos y comportamientos IA gobernados.

6.12.2. Integración funcional de los submodelos
A nivel funcional, cada submodelo cumple un rol específico, pero todos interactúan dentro del ai-gateway, la arquitectura C4 y el sistema N4.
(1) T-IA-Cog — La IA como tutor cognitivo disciplinar
Actúa sobre la formación del razonamiento: guía, indaga, andamia, explica, corrige, expone alternativas, ayuda a planificar.
 Su foco no es el código final, sino la estructura cognitiva del estudiante.
→ Es el submodelo pedagógico.

(2) E-IA-Proc — La IA como evaluador procesual auditivo
Analiza trazas, razonamiento, decisiones, evolución del código y evidencia N4.
 Evalúa comprensión, auditoría y metacognición, no califica numéricamente.
→ Es el submodelo evaluativo.

(3) S-IA-X — IA como simulador de roles profesionales
Simula PO, SM, clientes, entrevistadores, incidentes, DevSecOps.
 Traslada la IA al rol contextual profesional, fortaleciendo competencias reales.
→ Es el submodelo profesionalizante.

(4) AR-IA — Analista de riesgo cognitivo y ético
Detecta delegación excesiva, razonamiento superficial, dependencia, sesgos, violaciones éticas.
 Es un mecanismo preventivo que protege la salud cognitiva del aprendizaje.
→ Es el submodelo meta-cognitivo y ético.

(5) GOV-IA — Gobernanza institucional algorítmica
Implementa principios, estándares y marcos normativos: UNESCO, OECD, ISO/IEC 23894, IEEE.
 Monitorea cumplimiento, riesgos, auditoría y políticas.
→ Es el submodelo institucional.

(6) TC-N4 — Trazabilidad Cognitiva Institucional
Es el centro de gravedad del sistema.
 Registra el proceso completo, reconstruye el razonamiento, genera evidencia evaluativa y alimenta auditorías internas y externas.
→ Es el submodelo epistémico-evaluativo central.

6.12.3. Aportes originales del bloque de submodelos
El sistema integrado ofrece seis aportes inéditos para la literatura científica y la educación superior en ingeniería:

1. Reconfiguración del rol de la IA en la educación superior
La IA deja de ser un recurso de apoyo y pasa a ser un actor pedagógico con roles definidos, regulados, gobernados y evaluables.

2. Modelo procesual basado en razonamiento asistido–auditado
El bloque opera bajo un régimen epistémico inédito:
 la IA debe ayudar a razonar, pero también debe ser auditada por el estudiante.

3. Evaluación basada en trazabilidad cognitiva (N4)
Por primera vez, el proceso completo —no sólo el producto final— se convierte en evidencia evaluativa objetiva.

4. Integración formal de gobernanza algorítmica en el proceso educativo
La gobernanza deja de ser un documento externo para convertirse en parte operativa del sistema.

5. Ecosistema profesionalizante simulado con IA
Los simuladores conectan la formación con el ejercicio profesional real, gravitando hacia un modelo de aprendizaje auténtico y situado.

6. Marco institucional replicable
El bloque de submodelos constituye una unidad conceptual y técnica replicable por otras carreras, facultades y universidades.

6.12.4. Interdependencia sistémica: cómo funciona el ecosistema completo
El funcionamiento del bloque se organiza en tres circuitos integrados:

Circuito 1 — Razonamiento guiado (T-IA-Cog → N4)
El tutor IA guía el proceso → N4 registra cada paso → el estudiante explicita su razonamiento.

Circuito 2 — Auditoría y evaluación (E-IA-Proc + AR-IA → N4)
El evaluador IA lee la base N4 → el analista de riesgo detecta fragilidad cognitiva → se genera un Informe de Evaluación Cognitiva (IEC).

Circuito 3 — Gobernanza institucional (GOV-IA + N4 + Simuladores)
La gobernanza regula:
qué IA pueden usarse,


bajo qué restricciones,


qué riesgos son aceptables,


cómo se documentan decisiones,


qué datos se almacenan en N4.


Los simuladores generan evidencias auténticas que vuelven a N4.

6.12.5. Contribución doctoral del bloque de submodelos
Desde los criterios de evaluación de CONEAU, el bloque de submodelos representa un aporte doctoral por:
A. Originalidad
No existe en la literatura un modelo integrado que articule tutoría, evaluación procesual, simulación profesional, gobernanza y trazabilidad cognitiva.
B. Profundidad conceptual
Cada submodelo se sustenta en teorías cognitivas, pedagógicas, IA generativa, ingeniería de software y gobernanza algorítmica.
C. Rigor metodológico
Los submodelos son implementables, auditables y medibles; se integran con la metodología DBR aplicada en el Capítulo 7.
D. Valor institucional
El bloque sienta las bases para carreras AI-Native, estándares de calidad interna y políticas institucionales de IA.
E. Transferibilidad
Las universidades pueden adoptar el bloque —total o parcial— para regular el uso de IA en:
programación,


ingeniería,


educación técnica,


ciencias aplicadas,


formación docente.



6.12.6. Cierre: el bloque como núcleo operativo del modelo AI-Native
Los submodelos representan la traducción operativa del modelo AI-Native.
 Sin ellos, la arquitectura sería un sistema técnico sin pedagogía;
 con ellos, se convierte en una máquina cognitiva híbrida, capaz de:
dirigir la interacción humano–IA,


sostener el razonamiento,


auditar el proceso,


evaluar con validez,


gobernar la IA responsablemente,


producir evidencia sólida para acreditación.


El bloque constituye, por lo tanto, el núcleo operativo, cognitivo e institucional del modelo AI-Native propuesto por esta tesis.










7.2. SUBMODELO 1 — TUTOR IA DISCIPLINAR COGNITIVO (T-IA-Cog)
El tutor disciplinar es el agente cognitivo que interviene durante actividades, proyectos y prácticas guiadas.
Este submodelo define cómo debe comportarse una IA cuando enseña contenidos de programación bajo los principios del razonamiento asistido–auditado.

7.2.1. Fundamentación cognitiva
El T-IA-Cog se basa en:
Cognición distribuida (Hutchins, 1995).
Cognición extendida (Clark & Chalmers, 1998).
Teoría de carga cognitiva (Sweller, 1988).
Enfoques de metacognición (Zimmerman, 2002).
Su propósito es organizar y extender procesos cognitivos, no reemplazarlos.

7.2.2. Rol pedagógico
El tutor:
guía al estudiante,
promueve razonamiento explícito,
evita delegación acrítica,
fomenta planificación,
induce análisis de alternativas,
genera preguntas socráticas,
refuerza fundamentos conceptuales.
No entrega soluciones directas.
Interviene según reglas éticas y pedagógicas definidas por el ai-gateway.

7.2.3. Arquitectura interna del T-IA-Cog
El submodelo incorpora:
Módulo de Diagnóstico Cognitivo Instantáneo (DCI)
Detecta la fase cognitiva del estudiante: exploración, planificación, experimentación, depuración.
Módulo Socrático Adaptativo (MSA)
Genera preguntas basadas en:
complejidad,
comprensión previa,
errores conceptuales detectados,
nivel de apoyo necesario.
Módulo de Andamiaje Controlado (MAC)
Reduce gradualmente la ayuda a medida que el estudiante progresa.
Módulo de Explicación Profunda (MEP)
Produce explicaciones no solo de “qué hace el código”, sino:
por qué,
cómo se relaciona con principios,
qué alternativas existen,
qué riesgos introduce.

7.2.4. Integración con el ai-gateway
El T-IA-Cog opera como “modo” del CRPE (Motor Cognitivo-Pedagógico), y sus reglas se aplican:
durante prácticas en Moodle,
durante simulaciones,
durante depuración guiada,
durante prototipado conceptual.

7.2.5. Ejemplo operativo AI-Native
Prompt del estudiante:
“Explicame cómo funciona este algoritmo.”
Respuestas del T-IA-Cog:
Identifica si el estudiante comprende el problema.
Formula preguntas que reconstruyen contexto.
Explica estructura conceptual.
Pide justificación del razonamiento.
Evalúa consistencia lógica.
Registra decisiones y evidencias.
