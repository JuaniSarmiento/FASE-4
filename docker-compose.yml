# ============================================================================
# AI-Native MVP - Docker Compose Stack Completo
# ============================================================================
# Define el stack completo de la aplicación:
# - API Backend (FastAPI con uvicorn)
# - PostgreSQL Database
# - Redis Cache (para rate limiting y LLM cache)
#
# Uso:
#   docker-compose up -d          # Iniciar stack
#   docker-compose down           # Detener stack
#   docker-compose logs -f api    # Ver logs del API
#   docker-compose ps             # Ver estado de servicios
#   docker-compose exec api bash  # Shell en container API
# ============================================================================

version: '3.8'

services:
  # ==========================================================================
  # API Backend - FastAPI Application
  # ==========================================================================
  api:
    build:
      context: .
      dockerfile: Dockerfile
    image: ai-native-mvp:latest
    container_name: ai-native-api
    ports:
      - "8000:8000"
    environment:
      # Database configuration
      - DATABASE_URL=postgresql://ai_native:ai_native_password@postgres:5432/ai_native
      - DB_POOL_SIZE=80
      - DB_MAX_OVERFLOW=80
      - DB_POOL_TIMEOUT=5
      - DB_POOL_RECYCLE=3600

      # Redis configuration
      - REDIS_URL=redis://redis:6379/0
      - LLM_CACHE_ENABLED=true
      - LLM_CACHE_TTL=3600
      - LLM_CACHE_MAX_ENTRIES=1000

      # LLM Provider - Ollama (contenedor separado)
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2:3b}
      - OLLAMA_TEMPERATURE=${OLLAMA_TEMPERATURE:-0.7}
      - OLLAMA_TIMEOUT=${OLLAMA_TIMEOUT:-120}

      # Security
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-eUXGOdW7ByCGXzz_mCQWqLjZV0g5YyKXFMG0yknMvFY}
      - JWT_ALGORITHM=HS256
      - JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
      - JWT_REFRESH_TOKEN_EXPIRE_DAYS=7
      - SECRET_KEY=${SECRET_KEY:-eUXGOdW7ByCGXzz_mCQWqLjZV0g5YyKXFMG0yknMvFY}

      # Application
      - ENVIRONMENT=development
      - DEBUG=false
      - LOG_LEVEL=INFO

      # CORS
      - ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:8080

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy

    volumes:
      # Montar código en development para hot-reload (comentar en producción)
      - ./backend:/app/backend:ro

    networks:
      - ai-native-network

    restart: unless-stopped

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ==========================================================================
  # PostgreSQL Database
  # ==========================================================================
  postgres:
    image: postgres:15-alpine
    container_name: ai-native-postgres
    environment:
      - POSTGRES_DB=ai_native
      - POSTGRES_USER=ai_native
      - POSTGRES_PASSWORD=ai_native_password
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    ports:
      - "5432:5432"
    volumes:
      # Persistencia de datos
      - postgres_data:/var/lib/postgresql/data

      # Scripts de inicialización (opcional)
      # - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/init.sql:ro

    networks:
      - ai-native-network

    restart: unless-stopped

    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_native -d ai_native"]
      interval: 10s
      timeout: 5s
      retries: 5

    # Configuración de PostgreSQL para performance
    command:
      - "postgres"
      - "-c"
      - "max_connections=200"
      - "-c"
      - "shared_buffers=256MB"
      - "-c"
      - "effective_cache_size=1GB"
      - "-c"
      - "maintenance_work_mem=64MB"
      - "-c"
      - "checkpoint_completion_target=0.9"
      - "-c"
      - "wal_buffers=16MB"
      - "-c"
      - "default_statistics_target=100"
      - "-c"
      - "random_page_cost=1.1"
      - "-c"
      - "effective_io_concurrency=200"
      - "-c"
      - "work_mem=2MB"
      - "-c"
      - "min_wal_size=1GB"
      - "-c"
      - "max_wal_size=4GB"

  # ==========================================================================
  # Redis Cache
  # ==========================================================================
  redis:
    image: redis:7-alpine
    container_name: ai-native-redis
    ports:
      - "6379:6379"
    volumes:
      # Persistencia de datos (AOF - Append Only File)
      - redis_data:/data
    networks:
      - ai-native-network

    restart: unless-stopped

    # Configuración de Redis
    command:
      - "redis-server"
      - "--appendonly"
      - "yes"
      - "--appendfsync"
      - "everysec"
      - "--maxmemory"
      - "256mb"
      - "--maxmemory-policy"
      - "allkeys-lru"

    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # ==========================================================================
  # Ollama - Local LLM Server (usa modelos del host)
  # ==========================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: ai-native-ollama
    ports:
      - "11434:11434"
    environment:
      # Keep model loaded in memory permanently for instant responses
      - OLLAMA_KEEP_ALIVE=-1
    volumes:
      # Volumen persistente para modelos de Ollama
      - ollama_data:/root/.ollama
    networks:
      - ai-native-network
    restart: unless-stopped

    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # ==========================================================================
  # pgAdmin (opcional) - Administración de PostgreSQL
  # ==========================================================================
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: ai-native-pgadmin
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@ai-native.local
      - PGADMIN_DEFAULT_PASSWORD=admin
      - PGADMIN_CONFIG_SERVER_MODE=False
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    networks:
      - ai-native-network
    restart: unless-stopped
    profiles:
      - debug  # Solo se inicia con: docker-compose --profile debug up

  # ==========================================================================
  # Redis Commander (opcional) - Administración de Redis
  # ==========================================================================
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: ai-native-redis-commander
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8081:8081"
    networks:
      - ai-native-network
    restart: unless-stopped
    profiles:
      - debug  # Solo se inicia con: docker-compose --profile debug up

  # ==========================================================================
  # Prometheus (opcional) - Metrics Storage & Querying
  # ==========================================================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: ai-native-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.enable-lifecycle'
    networks:
      - ai-native-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - api
    profiles:
      - monitoring  # Solo se inicia con: docker-compose --profile monitoring up

  # ==========================================================================
  # Grafana (opcional) - Visualization & Dashboards
  # ==========================================================================
  grafana:
    image: grafana/grafana:10.2.0
    container_name: ai-native-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_SERVER_ROOT_URL=http://localhost:3001
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - ai-native-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - prometheus
    profiles:
      - monitoring  # Solo se inicia con: docker-compose --profile monitoring up

# ============================================================================
# Networks
# ============================================================================
networks:
  ai-native-network:
    driver: bridge
    name: ai-native-network

# ============================================================================
# Volumes (Persistencia de Datos)
# ============================================================================
volumes:
  postgres_data:
    name: ai-native-postgres-data
    driver: local

  redis_data:
    name: ai-native-redis-data
    driver: local

  pgadmin_data:
    name: ai-native-pgadmin-data
    driver: local

  prometheus_data:
    name: ai-native-prometheus-data
    driver: local

  grafana_data:
    name: ai-native-grafana-data
    driver: local

  ollama_data:
    name: ai-native-ollama-data
    driver: local

# ============================================================================
# Notas de Uso
# ============================================================================
#
# INICIAR STACK COMPLETO:
#   docker-compose up -d
#
# INICIAR CON HERRAMIENTAS DE DEBUG (pgAdmin + Redis Commander):
#   docker-compose --profile debug up -d
#
# VER LOGS:
#   docker-compose logs -f              # Todos los servicios
#   docker-compose logs -f api          # Solo API
#   docker-compose logs -f postgres     # Solo PostgreSQL
#   docker-compose logs -f redis        # Solo Redis
#
# EJECUTAR COMANDOS EN CONTAINERS:
#   docker-compose exec api bash                      # Shell en API
#   docker-compose exec postgres psql -U ai_native    # PostgreSQL shell
#   docker-compose exec redis redis-cli               # Redis shell
#
# RESTART SERVICIOS:
#   docker-compose restart api          # Solo API
#   docker-compose restart              # Todos los servicios
#
# DETENER Y ELIMINAR:
#   docker-compose down                 # Detener servicios (mantiene volúmenes)
#   docker-compose down -v              # Detener y ELIMINAR volúmenes (¡DANGER!)
#
# VER ESTADO:
#   docker-compose ps                   # Estado de servicios
#   docker-compose top                  # Procesos en ejecución
#
# REBUILD IMAGEN:
#   docker-compose build --no-cache api # Rebuild desde cero
#   docker-compose up -d --build        # Rebuild y reiniciar
#
# ACCEDER A INTERFACES WEB:
#   API Swagger: http://localhost:8000/docs
#   pgAdmin: http://localhost:5050 (admin@ai-native.local / admin)
#   Redis Commander: http://localhost:8081
#
# VARIABLES DE ENTORNO:
#   Las variables marcadas con ${VAR:-default} se leen desde .env del host
#   Crear archivo .env en el directorio raíz con:
#     LLM_PROVIDER=openai
#     OPENAI_API_KEY=sk-proj-...
#     JWT_SECRET_KEY=<generated_secret>
#
# TROUBLESHOOTING:
#   - Si API no inicia: docker-compose logs api
#   - Si PostgreSQL no conecta: docker-compose exec postgres pg_isready
#   - Si Redis no conecta: docker-compose exec redis redis-cli ping
#   - Verificar health checks: docker-compose ps
#
# PRODUCCIÓN:
#   1. Cambiar ENVIRONMENT=production
#   2. Generar JWT_SECRET_KEY seguro
#   3. Usar secretos externos (AWS Secrets Manager, Vault)
#   4. Comentar volume mount de código (./src:/app/src)
#   5. Configurar backup automático de postgres_data
#   6. Usar nginx como reverse proxy (agregar servicio nginx)
#
# ============================================================================